{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://i.imgur.com/FoKB5Z5.png\" align=\"left\" width=\"300\" height=\"250\" title=\"source: imgur.com\" /></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Program Code: J620-002-4:2020 \n",
    "\n",
    "## Program Name: FRONT-END SOFTWARE DEVELOPMENT\n",
    "\n",
    "## Title : P66 - Classification of MNIST Handwriting using Convolution Neural Network\n",
    "\n",
    "#### Name: \n",
    "\n",
    "#### IC Number:\n",
    "\n",
    "#### Date :\n",
    "\n",
    "#### Introduction : \n",
    "\n",
    "\n",
    "\n",
    "#### Conclusion :\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Beginner’s Guide to Keras: Digit Recognition in 30 Minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1:** Load the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.datasets import mnist\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2:** Load the mnist handwriting dataset from keras.datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11490434/11490434 [==============================] - 5s 0us/step\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "image_index = 35\n",
    "print(y_train[image_index])\n",
    "plt.imshow(x_train[image_index], cmap='Greys')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s verify the sizes of the training and testing datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we may also wish to explore the dependent variable, stored in y_train. Let’s print all labels until the digit that we visualized above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 0 4 1 9 2 1 3 1 4 3 5 3 6 1 7 2 8 6 9 4 0 9 1 1 2 4 3 2 7 3 8 6 9 0 5]\n"
     ]
    }
   ],
   "source": [
    "print(y_train[:image_index + 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3:** Cleaning/preparing the Data: reshape each image to the format of (M x N x 1). Also, normalize the image data by dividing each pixel value by 255 (since RGB value can range from 0 to 255):    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "x_train = np.array(x_train.reshape(x_train.shape[0], img_rows, img_cols, 1), 'float32')\n",
    "x_test = np.array(x_test.reshape(x_test.shape[0], img_rows, img_cols, 1), 'float32')\n",
    "\n",
    "x_train /= 255\n",
    "x_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "num_classes = 10\n",
    "\n",
    "y_train = to_categorical(y_train, num_classes)\n",
    "y_test = to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 4:** Design a Model: The model design process is the most complex factor, having a direct impact on the performance of the model. For this tutorial, we’ll use this design from the Keras Documentation.\n",
    "\n",
    "To create the model, we first initialize a sequential model. It creates an empty model object. The first step is to add a convolutional layer which takes the input image.\n",
    "\n",
    "Use:\n",
    "1. Conv2D with node size of 32, kernel_size=(3, 3)\n",
    "2. activation = ReLU\n",
    "3. Input share using number or img_rows and img_cols\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "     activation='relu',\n",
    "     input_shape=(img_rows, img_cols, 1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we add another convolutional layer, followed by a pooling layer (max poolsize - 2,2). Set it to 64 nodes, (3,3) and use ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we add a “dropout” layer. While neural networks are trained on huge datasets, a problem of overfitting may occur. To avoid this issue, we randomly drop units and their connections during the training process. In this case, we’ll drop 25% of the units:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dropout(0.25))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we add a flattening layer to convert the previous hidden layer into a 1D array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we’ve flattened the data into a 1D array, we can add a dense hidden layer (Node= 128, activation = ReLU), which is normal to a traditional neural network. Next, add another dropout layer (0.5) before adding a final dense layer which classifies the data (nodes = number of classes, activation = Softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile and Train Model\n",
    "In the model design process, we’ve created an empty model without an objective function. We need to compile the model and specify a loss function, an optimizer function and a metric to assess model performance.\n",
    "\n",
    "We need to use a sparse_categorical_crossentropy loss function in case we have an integer-dependent variable. For a vector-based dependent variable like a ten-size array as the output of each test case, use categorical_crossentropy. In this example, we’ll use the adam optimizer. The metric is the basis of assessment of our model performance, though it’s only for us to judge and isn’t used in the training step.\n",
    "\n",
    "Reference: This exercise is adapted from https://www.sitepoint.com/keras-digit-recognition-tutorial/\n",
    "\n",
    "**Step 5:** Compile the model using the above settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "      optimizer='adam',\n",
    "      metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We’re now ready to train the model using the .fit() method. We need to specify an epoch and batch size when training the model. An epoch is one forward pass and one backward pass of all training examples. A batch size is the number of training examples in one forward or backward pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "469/469 [==============================] - 84s 180ms/step - loss: 0.2337 - accuracy: 0.9295 - val_loss: 0.0490 - val_accuracy: 0.9846\n",
      "Epoch 2/10\n",
      "469/469 [==============================] - 86s 183ms/step - loss: 0.0861 - accuracy: 0.9746 - val_loss: 0.0416 - val_accuracy: 0.9875\n",
      "Epoch 3/10\n",
      "469/469 [==============================] - 87s 185ms/step - loss: 0.0637 - accuracy: 0.9809 - val_loss: 0.0329 - val_accuracy: 0.9887\n",
      "Epoch 4/10\n",
      "469/469 [==============================] - 89s 189ms/step - loss: 0.0505 - accuracy: 0.9850 - val_loss: 0.0344 - val_accuracy: 0.9891\n",
      "Epoch 5/10\n",
      "469/469 [==============================] - 86s 184ms/step - loss: 0.0449 - accuracy: 0.9863 - val_loss: 0.0276 - val_accuracy: 0.9901\n",
      "Epoch 6/10\n",
      "469/469 [==============================] - 88s 187ms/step - loss: 0.0388 - accuracy: 0.9877 - val_loss: 0.0275 - val_accuracy: 0.9906\n",
      "Epoch 7/10\n",
      "469/469 [==============================] - 90s 192ms/step - loss: 0.0337 - accuracy: 0.9890 - val_loss: 0.0246 - val_accuracy: 0.9918\n",
      "Epoch 8/10\n",
      "469/469 [==============================] - 88s 187ms/step - loss: 0.0310 - accuracy: 0.9899 - val_loss: 0.0268 - val_accuracy: 0.9914\n",
      "Epoch 9/10\n",
      "469/469 [==============================] - 88s 187ms/step - loss: 0.0283 - accuracy: 0.9908 - val_loss: 0.0282 - val_accuracy: 0.9910\n",
      "Epoch 10/10\n",
      "469/469 [==============================] - 90s 192ms/step - loss: 0.0240 - accuracy: 0.9922 - val_loss: 0.0325 - val_accuracy: 0.9910\n",
      "Test loss: 0.03252638876438141\n",
      "Test accuracy: 0.9909999966621399\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "epochs = 10\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 6:** Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 7:** Save the model (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"test_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 8:** Perform some prediction? How well will your model perform?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "im = imageio.imread(\"https://i.imgur.com/a3Rql9C.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gray = np.dot(im[...,:3], [0.299, 0.587, 0.114])\n",
    "plt.imshow(gray, cmap = plt.get_cmap('gray'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape the image\n",
    "gray = gray.reshape(1, img_rows, img_cols, 1)\n",
    "\n",
    "# normalize image\n",
    "gray /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model\n",
    "from keras.models import load_model\n",
    "model = load_model(\"test_model.h5\")\n",
    "\n",
    "# predict digit\n",
    "prediction = model.predict(gray)\n",
    "print(prediction.argmax())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
